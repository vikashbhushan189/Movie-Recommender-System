{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3536491e-95ea-4f30-82fc-8446a83b8d02",
   "metadata": {},
   "source": [
    "# ðŸŽ¬ Advanced Movie Recommender System\n",
    "\n",
    "This Jupyter Notebook serves as the comprehensive development environment for an advanced movie recommendation system. It covers data loading, extensive preprocessing and feature engineering, implementation of various recommendation models (popularity-based, content-based, collaborative filtering, and hybrid), and their evaluation.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1.  [**Setup and Data Loading**](#setup-data-loading)\n",
    "2.  [**Phase 1: Popularity-Based Recommender & Core Preprocessing**](#popularity-recommender)\n",
    "3.  [**Phase 2: Advanced Feature Engineering for Content-Based Models**](#advanced-feature-engineering)\n",
    "4.  [**Phase 3: Enhancing Recommendation Models**](#enhancing-models)\n",
    "    *   [3.1. Content-Based Recommenders (Plot & Metadata)](#content-based-recs)\n",
    "    *   [3.2. Simple Hybrid Recommender (Content + Weighted Rating)](#simple-hybrid)\n",
    "    *   [3.3. Collaborative Filtering (SVD)](#collaborative-filtering)\n",
    "5.  [**Phase 4: Evaluation and Metrics**](#evaluation-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d884bd-aa6f-4b8a-90e2-3ae169de5e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK successfully imported and initialized.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "# NLTK imports and dummies \n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    print(\"NLTK successfully imported and initialized.\")\n",
    "except ImportError:\n",
    "    print(\"NLTK not found. Text preprocessing (lemmatization/stopwords) will be skipped.\")\n",
    "    print(\"Please install it: pip install nltk && python -c 'import nltk; nltk.download(\\\"punkt\\\"); nltk.download(\\\"wordnet\\\"); nltk.download(\\\"stopwords\\\")'\")\n",
    "    def word_tokenize(text): return str(text).split()\n",
    "    class DummyLemmatizer:\n",
    "        def lemmatize(self, word): return word\n",
    "    lemmatizer = DummyLemmatizer()\n",
    "    class DummyStopwords:\n",
    "        def words(self, lang): return set()\n",
    "    stopwords_instance = DummyStopwords()\n",
    "    stop_words = stopwords_instance.words('english')\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc32929-8db3-4270-9411-5a2e6aece195",
   "metadata": {},
   "source": [
    "<a id='setup-data-loading'></a>\n",
    "## 1. Setup and Data Loading\n",
    "\n",
    "In this section, we load all the necessary datasets:\n",
    "- `movies_metadata.csv`: Contains core movie information including title, overview, vote counts, and averages (used for content features and popular charts).\n",
    "- `credits.csv`: Contains cast and crew information (used for metadata features).\n",
    "- `keywords.csv`: Contains associated keywords (used for metadata features).\n",
    "- `ratings_small.csv`: Contains user ratings (used for collaborative filtering and evaluation ground truth).\n",
    "- `links.csv`: Crucial for mapping MovieLens IDs (used in `ratings_small.csv`) to TMDB IDs (used in `movies_metadata.csv`) to establish a consistent ID space.\n",
    "\n",
    "All these files are expected to be located in a `data/` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e6ad1b-fcf3-4247-9d2a-35e5b4d984dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data ---\n",
      "All CSV files loaded successfully (including links.csv).\n"
     ]
    }
   ],
   "source": [
    "# --- 0. Data Loading ---\n",
    "print(\"--- Loading Data ---\")\n",
    "try:\n",
    "    metadata = pd.read_csv('data/movies_metadata.csv', low_memory=False)\n",
    "    credits = pd.read_csv('data/credits.csv')\n",
    "    keywords = pd.read_csv('data/keywords.csv')\n",
    "    ratings = pd.read_csv('data/ratings_small.csv')\n",
    "    links = pd.read_csv('data/links.csv') # Should contain movieId, imdbId, tmdbId\n",
    "    print(\"All CSV files loaded successfully (including links.csv).\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading CSV files. Make sure 'data/' directory exists and contains: movies_metadata.csv, credits.csv, keywords.csv, ratings_small.csv, and links.csv. Error: {e}\")\n",
    "    print(\"Exiting script as essential data is missing.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5777472-ffc2-470a-9a12-a76bb761b985",
   "metadata": {},
   "source": [
    "<a id='popularity-recommender'></a>\n",
    "## 2. Phase 1: Popularity-Based Recommender & Core Preprocessing\n",
    "\n",
    "This phase focuses on two key aspects:\n",
    "\n",
    "1.  **Building a Simple Top Movies Chart:** We utilize a weighted rating formula, similar to IMDb's, to rank movies. This prevents movies with few (but high) ratings from unfairly dominating the chart.\n",
    "    *   **Formula:** Weighted Rating (WR) = (v / (v + m)) * R + (m / (v + m)) * C\n",
    "        *   `v`: `vote_count` (number of votes)\n",
    "        *   `m`: minimum votes required to be in the chart (set at the 90th percentile of `vote_count` across the dataset)\n",
    "        *   `R`: `vote_average` (average rating)\n",
    "        *   `C`: The mean `vote_average` across the entire dataset.\n",
    "\n",
    "2.  **Initial Data Integration and ID Alignment:** Crucially, we merge the disparate datasets (`metadata`, `credits`, `keywords`) into a single master DataFrame (`df`). A critical step is to align movie IDs. `movies_metadata.csv` uses TMDB IDs, while `ratings_small.csv` uses MovieLens IDs. `links.csv` provides the necessary bridge to map `MovieLensId` to `TMDBId`, allowing us to connect our content data with user ratings. This creates a unified `movieId` column in our main `df` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1bc3e1-4fb1-48bf-9f01-0d59e32d00f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 1: Simple Top Movies Chart Recommender Setup & Data Cleaning ---\n",
      "Merged DataFrame initial shape: 45432 rows, 27 columns\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Phase 1: Simple Top Movies Chart Recommender & Preprocessing ---\n",
    "print(\"\\n--- Phase 1: Simple Top Movies Chart Recommender Setup & Data Cleaning ---\")\n",
    "\n",
    "metadata = metadata[pd.to_numeric(metadata['id'], errors='coerce').notnull()]\n",
    "metadata['id'] = metadata['id'].astype('int')\n",
    "\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "\n",
    "df = metadata.merge(credits, on='id', how='inner')\n",
    "df = df.merge(keywords, on='id', how='inner')\n",
    "df.drop_duplicates(subset=['id'], inplace=True)\n",
    "print(f\"Merged DataFrame initial shape: {df.shape[0]} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5ddef4-aa2e-42b7-8c9c-018726146f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Creating Movie ID Mappings ---\n",
      "Main DataFrame `df` now aligned with MovieLens IDs (via `df['movieId']`). Shape: (45432, 28)\n"
     ]
    }
   ],
   "source": [
    "# --- Create MovieID mapping between ratings and metadata ---\n",
    "print(\"\\n--- Creating Movie ID Mappings ---\")\n",
    "links = links[pd.to_numeric(links['tmdbId'], errors='coerce').notnull()]\n",
    "links['tmdbId'] = links['tmdbId'].astype('int')\n",
    "\n",
    "movieId_to_tmdbId = links.set_index('movieId')['tmdbId'].to_dict()\n",
    "tmdbId_to_movieId = {v: k for k, v in movieId_to_tmdbId.items()}\n",
    "\n",
    "df['movieId'] = df['id'].map(tmdbId_to_movieId)\n",
    "df.dropna(subset=['movieId'], inplace=True) # Drop movies without a MovieLens ID mapping\n",
    "df['movieId'] = df['movieId'].astype('int')\n",
    "\n",
    "print(f\"Main DataFrame `df` now aligned with MovieLens IDs (via `df['movieId']`). Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75fcd86d-4e65-4c16-a763-827edc5f316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean vote average (C): 5.62\n",
      "Minimum votes required (m for chart): 160\n",
      "\n",
      "--- Top 15 Movies Chart (based on Weighted Rating) ---\n",
      "                                 title  vote_count  vote_average     score\n",
      "314           The Shawshank Redemption      8358.0           8.5  8.445874\n",
      "837                      The Godfather      6024.0           8.5  8.425445\n",
      "10357      Dilwale Dulhania Le Jayenge       661.0           9.1  8.421501\n",
      "12541                  The Dark Knight     12269.0           8.3  8.265480\n",
      "2858                        Fight Club      9678.0           8.3  8.256389\n",
      "292                       Pulp Fiction      8670.0           8.3  8.251410\n",
      "522                   Schindler's List      4436.0           8.3  8.206648\n",
      "23818                         Whiplash      4376.0           8.3  8.205413\n",
      "5505                     Spirited Away      3968.0           8.3  8.196064\n",
      "2223                 Life Is Beautiful      3643.0           8.3  8.187182\n",
      "1187            The Godfather: Part II      3418.0           8.3  8.180087\n",
      "1161   One Flew Over the Cuckoo's Nest      3001.0           8.3  8.164268\n",
      "351                       Forrest Gump      8147.0           8.2  8.150277\n",
      "1163           The Empire Strikes Back      5998.0           8.2  8.132925\n",
      "1185                            Psycho      2405.0           8.3  8.132730\n"
     ]
    }
   ],
   "source": [
    "# --- Robust Missing Value Handling & Type Conversion for Numerical Features ---\n",
    "df['vote_count'] = pd.to_numeric(df['vote_count'], errors='coerce').fillna(0)\n",
    "df['vote_average'] = pd.to_numeric(df['vote_average'], errors='coerce')\n",
    "\n",
    "C = df['vote_average'].mean()\n",
    "df['vote_average'] = df['vote_average'].fillna(C)\n",
    "print(f\"Overall Mean vote average (C): {C:.2f}\")\n",
    "\n",
    "m = df['vote_count'].quantile(0.90)\n",
    "print(f\"Minimum votes required (m for chart): {m:.0f}\")\n",
    "\n",
    "def weighted_rating(x, m_val, c_val):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    if v == 0:\n",
    "        return c_val\n",
    "    return (v / (v + m_val)) * R + (m_val / (m + v)) * c_val\n",
    "\n",
    "df['score'] = df.apply(lambda x: weighted_rating(x, m_val=m, c_val=C), axis=1)\n",
    "\n",
    "print(\"\\n--- Top 15 Movies Chart (based on Weighted Rating) ---\")\n",
    "print(df[['title', 'vote_count', 'vote_average', 'score']].sort_values('score', ascending=False).head(15).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de211e-f17c-4c7e-8296-b7fe8c39302f",
   "metadata": {},
   "source": [
    "<a id='advanced-feature-engineering'></a>\n",
    "## 3. Phase 2: Advanced Feature Engineering for Content-Based Models\n",
    "\n",
    "This section prepares the data for sophisticated content-based recommendation.\n",
    "\n",
    "The key improvements here are:\n",
    "\n",
    "1.  **Robust String Parsing:** Safely converts stringified lists (e.g., `cast`, `genres`, `keywords`) into actual Python lists using `literal_eval`, handling missing values and malformed strings gracefully.\n",
    "2.  **Structured Feature Extraction:** Specific helper functions `get_director` and `get_top_n_names` extract and format relevant information (e.g., top 3 cast members, director) into clean lists of strings.\n",
    "3.  **Advanced Text Preprocessing:**\n",
    "    *   **Normalization:** Lowercasing and removing non-alphabetic characters.\n",
    "    *   **Tokenization:** Breaking text into words.\n",
    "    *   **Stopword Removal:** Eliminating common words (like \"the\", \"a\") that don't add semantic value.\n",
    "    *   **Lemmatization:** Reducing words to their base or dictionary form (e.g., \"running\" -> \"run\", \"better\" -> \"good\"). This significantly improves text feature quality by ensuring different word forms are treated as the same concept. This is applied to `overview` (for plot-based) and to the individual components that form the 'metadata soup'.\n",
    "4.  **Creating a \"Processed Soup\":** A single string (`processed_soup`) is created by combining cleaned versions of director, top cast, keywords, and genres. This serves as the consolidated textual input for metadata-based similarity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2930cd3-1465-47ce-b263-e9970fb619a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Advanced Feature Extraction & Text Preprocessing ---\n",
      "Data preprocessing and feature engineering complete.\n",
      "Final DataFrame shape: (45432, 36)\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Advanced Feature Extraction and Text Preprocessing ---\n",
    "print(\"\\n--- Advanced Feature Extraction & Text Preprocessing ---\")\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return literal_eval(val)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "features_to_parse = ['cast', 'crew', 'keywords', 'genres']\n",
    "for feature in features_to_parse:\n",
    "    df[feature] = df[feature].apply(safe_literal_eval)\n",
    "\n",
    "def get_director(crew_list):\n",
    "    for member in crew_list:\n",
    "        if isinstance(member, dict) and member.get('job') == 'Director':\n",
    "            return member.get('name', '')\n",
    "    return ''\n",
    "\n",
    "def get_top_n_names(list_of_dicts, n=3):\n",
    "    names = []\n",
    "    if isinstance(list_of_dicts, list):\n",
    "        for item in list_of_dicts:\n",
    "            if isinstance(item, dict) and 'name' in item:\n",
    "                names.append(item['name'])\n",
    "    return names[:n]\n",
    "\n",
    "df['director'] = df['crew'].apply(get_director)\n",
    "df['cast'] = df['cast'].apply(get_top_n_names)\n",
    "df['keywords'] = df['keywords'].apply(get_top_n_names)\n",
    "df['genres'] = df['genres'].apply(get_top_n_names)\n",
    "\n",
    "df['overview'] = df['overview'].fillna('')\n",
    "\n",
    "def clean_and_lemmatize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    processed_tokens = []\n",
    "    for word in tokens:\n",
    "        if word not in stop_words:\n",
    "            processed_tokens.append(lemmatizer.lemmatize(word))\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "df['clean_overview'] = df['overview'].apply(clean_and_lemmatize_text)\n",
    "\n",
    "def clean_list_of_strings(lst):\n",
    "    if isinstance(lst, list):\n",
    "        return [clean_and_lemmatize_text(item) for item in lst]\n",
    "    return []\n",
    "\n",
    "df['processed_keywords'] = df['keywords'].apply(clean_list_of_strings)\n",
    "df['processed_cast'] = df['cast'].apply(clean_list_of_strings)\n",
    "df['processed_genres'] = df['genres'].apply(clean_list_of_strings)\n",
    "df['processed_director'] = df['director'].apply(clean_and_lemmatize_text)\n",
    "\n",
    "def create_processed_soup(x):\n",
    "    keywords_str = ' '.join(x['processed_keywords'])\n",
    "    cast_str = ' '.join(x['processed_cast'])\n",
    "    genres_str = ' '.join(x['processed_genres'])\n",
    "    director_str = x['processed_director']\n",
    "    soup = f\"{keywords_str} {cast_str} {director_str} {genres_str}\"\n",
    "    return ' '.join(soup.split())\n",
    "\n",
    "df['processed_soup'] = df.apply(create_processed_soup, axis=1)\n",
    "\n",
    "print(\"Data preprocessing and feature engineering complete.\")\n",
    "print(f\"Final DataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba97905-0b51-4ea1-bb6a-2dbb90162480",
   "metadata": {},
   "source": [
    "<a id='enhancing-models'></a>\n",
    "## 4. Phase 3: Enhancing Recommendation Models\n",
    "\n",
    "With a thoroughly preprocessed and enriched dataset, we now implement and enhance various recommendation models.\n",
    "\n",
    "1.  **Content-Based Recommenders:**\n",
    "    *   **Plot-Based:** Utilizes `TfidfVectorizer` on the `clean_overview` column. TF-IDF highlights words unique to a document, reducing the weight of common words.\n",
    "    *   **Metadata-Based:** Utilizes `CountVectorizer` on the `processed_soup` (director, cast, keywords, genres). CountVectorizer counts word occurrences.\n",
    "    *   Both models employ **Cosine Similarity** to measure the resemblance between movie content vectors. Recommendations are then generated by finding movies most similar to a given input movie.\n",
    "\n",
    "2.  **Simple Hybrid Recommender (Content + Weighted Rating):** This model combines the content similarity score with the movie's overall `score` (weighted rating) to re-rank content-based recommendations. This aims to blend item-to-item similarity with a general measure of quality/popularity.\n",
    "\n",
    "3.  **Collaborative Filtering (SVD):** Uses Singular Value Decomposition (SVD) from the `surprise` library to predict user-item ratings based on historical rating patterns. This enables personalized recommendations by identifying users with similar tastes. The model is trained on the `ratings_small.csv` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df2e7d5-6b9a-4c71-9d68-fcf7f350384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Enhancing Recommendation Models ---\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Enhancing Recommendation Models ---\n",
    "print(\"\\n--- Enhancing Recommendation Models ---\")\n",
    "\n",
    "# Create a dictionary mapping unique titles to their *first* corresponding DataFrame index.\n",
    "title_to_index = pd.Series(df.index.values, index=df['title']).drop_duplicates().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29daaff-8af5-453c-80d4-48592637c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Plot-Based Recommender Setup (TF-IDF) --\n",
      "TF-IDF Matrix (Plot) Shape: (45432, 18744)\n",
      "\n",
      "--- Testing Refined Plot-Based Recommender ---\n",
      "Recommendations for 'The Dark Knight Rises':\n",
      "                         title  similarity_score\n",
      "27929             Remonstrance          0.176185\n",
      "11286  Sketches of Frank Gehry          0.172817\n",
      "830                   Basquiat          0.168594\n",
      "17139              High School          0.168499\n",
      "28091             Foreign Body          0.162601\n",
      "31127    Nos amis les Terriens          0.161120\n",
      "18319    Waiting for Happiness          0.149192\n",
      "31785  Ghost of Goodnight Lane          0.146221\n",
      "34876  Winter Evening in Gagry          0.142608\n",
      "2120           Elstree Calling          0.134659\n"
     ]
    }
   ],
   "source": [
    "# A. Plot-Based Recommender (using 'clean_overview')\n",
    "print(\"\\n-- Plot-Based Recommender Setup (TF-IDF) --\")\n",
    "tfidf_plot = TfidfVectorizer(stop_words='english', max_df=0.8, min_df=5)\n",
    "tfidf_matrix_plot = tfidf_plot.fit_transform(df['clean_overview'])\n",
    "print(f\"TF-IDF Matrix (Plot) Shape: {tfidf_matrix_plot.shape}\")\n",
    "\n",
    "def get_recommendations_plot_refined(title, tfidf_matrix_p=tfidf_matrix_plot, df_movies=df, title_map=title_to_index):\n",
    "    if title not in title_map:\n",
    "        return pd.DataFrame([{\"title\": \"Movie not found. Please check the title (case-sensitive).\", \"similarity_score\": np.nan}])\n",
    "\n",
    "    idx = title_map[title]\n",
    "    movie_vector = tfidf_matrix_p[idx]\n",
    "    sim_scores = cosine_similarity(movie_vector, tfidf_matrix_p)\n",
    "    sim_scores = list(enumerate(sim_scores[0]))\n",
    "\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = [score for score in sim_scores if score[0] != idx]\n",
    "    sim_scores = sim_scores[:10]\n",
    "\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    recommended_movies = df_movies.iloc[movie_indices].copy()\n",
    "    recommended_movies['similarity_score'] = [s[1] for s in sim_scores]\n",
    "    return recommended_movies[['title', 'similarity_score']]\n",
    "\n",
    "print(\"\\n--- Testing Refined Plot-Based Recommender ---\")\n",
    "print(\"Recommendations for 'The Dark Knight Rises':\")\n",
    "print(get_recommendations_plot_refined('The Dark Knight Rises'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7103566-93d2-40d8-9f15-0ec53a01e5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Metadata-Based Recommender Setup (CountVectorizer) --\n",
      "CountVectorizer Matrix (Metadata) Shape: (45432, 52560)\n",
      "\n",
      "--- Testing Refined Metadata-Based Recommender ---\n",
      "Recommendations for 'The Avengers':\n",
      "                                                   title  similarity_score\n",
      "28631           Sold Out: A Threevening with Kevin Smith          0.250000\n",
      "45855           Bird's-Eye View of Dock Front, Galveston          0.250000\n",
      "24629                   TINY: A Story About Living Small          0.243332\n",
      "32651                                 Star Spangled Girl          0.235702\n",
      "27677                                        Santa Claus          0.226134\n",
      "1934                             The Million Dollar Duck          0.223607\n",
      "9838                                           Blackball          0.223607\n",
      "17980                                 Me and the Colonel          0.223607\n",
      "18057  The Enchanted World of Danny Kaye: The Emperor...          0.223607\n",
      "26096                               The Hire: Powder Keg          0.223607\n"
     ]
    }
   ],
   "source": [
    "# B. Metadata-Based Recommender (using 'processed_soup')\n",
    "print(\"\\n-- Metadata-Based Recommender Setup (CountVectorizer) --\")\n",
    "count_metadata = CountVectorizer(stop_words='english')\n",
    "cv_matrix_metadata = count_metadata.fit_transform(df['processed_soup'])\n",
    "print(f\"CountVectorizer Matrix (Metadata) Shape: {cv_matrix_metadata.shape}\")\n",
    "\n",
    "def get_recommendations_metadata_refined(title, cv_matrix_m=cv_matrix_metadata, df_movies=df, title_map=title_to_index):\n",
    "    if title not in title_map:\n",
    "        return pd.DataFrame([{\"title\": \"Movie not found. Please check the title (case-sensitive).\", \"similarity_score\": np.nan}])\n",
    "\n",
    "    idx = title_map[title]\n",
    "    movie_vector = cv_matrix_m[idx]\n",
    "    sim_scores = cosine_similarity(movie_vector, cv_matrix_m)\n",
    "    sim_scores = list(enumerate(sim_scores[0]))\n",
    "\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = [score for score in sim_scores if score[0] != idx]\n",
    "    sim_scores = sim_scores[:10]\n",
    "\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    recommended_movies = df_movies.iloc[movie_indices].copy()\n",
    "    recommended_movies['similarity_score'] = [s[1] for s in sim_scores]\n",
    "    return recommended_movies[['title', 'similarity_score']]\n",
    "\n",
    "print(\"\\n--- Testing Refined Metadata-Based Recommender ---\")\n",
    "print(\"Recommendations for 'The Avengers':\")\n",
    "print(get_recommendations_metadata_refined('The Avengers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1064a03-a968-4566-a7a5-243cb97c4531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Simple Hybrid Recommender Setup --\n",
      "\n",
      "--- Testing Simple Hybrid Recommender (Content + Weighted Rating) ---\n",
      "Hybrid Recommendations for 'The Dark Knight Rises' (using Plot content):\n",
      "                         title  hybrid_ranking_score  content_similarity  \\\n",
      "27929             Remonstrance                   NaN                 NaN   \n",
      "11286  Sketches of Frank Gehry                   NaN                 NaN   \n",
      "830                   Basquiat                   NaN                 NaN   \n",
      "17139              High School                   NaN                 NaN   \n",
      "28091             Foreign Body                   NaN                 NaN   \n",
      "31127    Nos amis les Terriens                   NaN                 NaN   \n",
      "18319    Waiting for Happiness                   NaN                 NaN   \n",
      "31785  Ghost of Goodnight Lane                   NaN                 NaN   \n",
      "34876  Winter Evening in Gagry                   NaN                 NaN   \n",
      "2120           Elstree Calling                   NaN                 NaN   \n",
      "\n",
      "          score  vote_average  \n",
      "27929  5.614612           5.0  \n",
      "11286  5.654748           6.3  \n",
      "830    5.988920           6.6  \n",
      "17139  5.672171           6.9  \n",
      "28091  5.616991           5.5  \n",
      "31127  5.647271           6.8  \n",
      "18319  5.550614           4.0  \n",
      "31785  5.553565           4.4  \n",
      "34876  5.623163           6.0  \n",
      "2120   5.596003           3.8  \n"
     ]
    }
   ],
   "source": [
    "# C. Simple Hybrid Recommender (Content-Based + Weighted Rating)\n",
    "print(\"\\n-- Simple Hybrid Recommender Setup --\")\n",
    "def get_hybrid_recommendations_content_weighted(title, content_source='plot', num_recommendations=10, df_movies=df, title_map=title_to_index):\n",
    "    if title not in title_map:\n",
    "        return pd.DataFrame([{\"title\": \"Movie not found. Please check the title (case-sensitive).\", \"hybrid_ranking_score\": np.nan}])\n",
    "\n",
    "    idx = title_map[title]\n",
    "\n",
    "    if content_source == 'plot':\n",
    "        matrix = tfidf_matrix_plot\n",
    "    elif content_source == 'metadata':\n",
    "        matrix = cv_matrix_metadata\n",
    "    else:\n",
    "        raise ValueError(\"content_source must be 'plot' or 'metadata'.\")\n",
    "\n",
    "    movie_vector = matrix[idx]\n",
    "    sim_scores_raw = cosine_similarity(movie_vector, matrix)[0]\n",
    "\n",
    "    candidate_scores = [(i, score) for i, score in enumerate(sim_scores_raw) if i != idx]\n",
    "    candidate_scores = sorted(candidate_scores, key=lambda x: x[1], reverse=True)[:50]\n",
    "\n",
    "    candidate_movie_indices = [i[0] for i in candidate_scores]\n",
    "\n",
    "    candidate_df = df_movies.iloc[candidate_movie_indices].copy()\n",
    "    candidate_similarity_map = {original_idx: score for original_idx, score in candidate_scores}\n",
    "    candidate_df['content_similarity'] = candidate_df.index.map(candidate_similarity_map)\n",
    "    \n",
    "    candidate_df['score'] = pd.to_numeric(candidate_df['score'], errors='coerce')\n",
    "    max_score = candidate_df['score'].max()\n",
    "    candidate_df['normalized_score'] = candidate_df['score'] / max_score if max_score > 0 else 0\n",
    "\n",
    "    content_weight = 0.7\n",
    "    popularity_weight = 0.3\n",
    "\n",
    "    candidate_df['hybrid_ranking_score'] = (candidate_df['content_similarity'] * content_weight) + \\\n",
    "                                         (candidate_df['normalized_score'] * popularity_weight)\n",
    "\n",
    "    final_recommendations = candidate_df.sort_values(by='hybrid_ranking_score', ascending=False)\n",
    "\n",
    "    return final_recommendations[['title', 'hybrid_ranking_score', 'content_similarity', 'score', 'vote_average']].head(num_recommendations)\n",
    "\n",
    "print(\"\\n--- Testing Simple Hybrid Recommender (Content + Weighted Rating) ---\")\n",
    "print(\"Hybrid Recommendations for 'The Dark Knight Rises' (using Plot content):\")\n",
    "print(get_hybrid_recommendations_content_weighted('The Dark Knight Rises', content_source='plot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b5ab3-ddaa-4993-b88b-eac739e74ff0",
   "metadata": {},
   "source": [
    "<a id='collaborative-filtering'></a>\n",
    "### 4.4. Collaborative Filtering (SVD)\n",
    "\n",
    "Collaborative Filtering (CF) focuses on leveraging user-item interaction data (ratings) to make recommendations. The underlying assumption is that users who agreed in the past on their ratings will likely agree again in the future.\n",
    "\n",
    "We use **Singular Value Decomposition (SVD)** from the `surprise` library. SVD is a matrix factorization technique that decomposes the user-item interaction matrix into a set of latent factors for both users and items, which are then used to predict ratings for unrated items.\n",
    "\n",
    "Key aspects:\n",
    "-   `ratings_small.csv` provides the `userId`, `movieId`, and `rating`.\n",
    "-   The `movieId`s from `ratings_small.csv` are consistent with the `movieId` column we added to our main `df` using `links.csv`, ensuring proper mapping to movie metadata.\n",
    "-   `cross_validate` provides standard evaluation metrics for CF like **RMSE (Root Mean Squared Error)** and **MAE (Mean Absolute Error)**, which measure the accuracy of rating predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "631e58ba-29aa-413b-9224-bb1132e33460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Collaborative Filtering (SVD) ---\n",
      "Performing cross-validation for SVD...\n",
      "Training SVD model on full dataset for general recommendations...\n",
      "SVD model trained on full dataset.\n",
      "Testing SVD prediction for user 1 on movie 1 ('Toy Story').\n",
      "Predicted rating: 2.79\n",
      "\n",
      "--- Testing Collaborative Filtering (SVD) Recommender for User 1 (trained on full data) ---\n",
      "Top 10 SVD Recommendations for User ID 1:\n",
      "   movieId  predicted_rating                                title  vote_average  vote_count     score\n",
      "0     2318          3.703517                            Happiness           7.4       197.0  6.601548\n",
      "1      318          3.603997             The Shawshank Redemption           8.5      8358.0  8.445874\n",
      "2     1204          3.582036                   Lawrence of Arabia           7.8       870.0  7.461119\n",
      "3     2542          3.581224  Lock, Stock and Two Smoking Barrels           7.5      1671.0  7.335583\n",
      "4     1203          3.523435                         12 Angry Men           8.2      2130.0  8.019630\n",
      "5      745          3.512494                        A Close Shave           7.5       223.0  6.713975\n",
      "6     1252          3.500850                            Chinatown           7.9       939.0  7.567837\n",
      "7     1136          3.494576      Monty Python and the Holy Grail           7.8      1742.0  7.616484\n",
      "8       50          3.489723                   The Usual Suspects           8.1      3334.0  7.986363\n",
      "9     2019          3.481000                        Seven Samurai           8.2       892.0  7.807369\n"
     ]
    }
   ],
   "source": [
    "# D. Collaborative Filtering (SVD)\n",
    "print(\"\\n--- Collaborative Filtering (SVD) ---\")\n",
    "df_rated_movies = df[df['movieId'].notna()].copy()\n",
    "\n",
    "if not ratings.empty:\n",
    "    reader = Reader(rating_scale=(0.5, 5)) # DEFINED READER HERE\n",
    "    full_data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader) # DEFINED DATA HERE\n",
    "\n",
    "    print(\"Performing cross-validation for SVD...\")\n",
    "    svd = SVD()\n",
    "    cross_validate(svd, full_data, measures=['RMSE', 'MAE'], cv=5, verbose=False) # USE full_data HERE\n",
    "\n",
    "    print(\"Training SVD model on full dataset for general recommendations...\")\n",
    "    trainset_full = full_data.build_full_trainset()\n",
    "    svd_full = SVD()\n",
    "    svd_full.fit(trainset_full)\n",
    "    print(\"SVD model trained on full dataset.\")\n",
    "\n",
    "    user_id_test = 1\n",
    "    if not df_rated_movies.empty and df_rated_movies['movieId'].isin(ratings['movieId']).any():\n",
    "        movie_id_test_from_ratings = df_rated_movies[df_rated_movies['movieId'].isin(ratings['movieId'])]['movieId'].iloc[0]\n",
    "        movie_title_for_test = df_rated_movies[df_rated_movies['movieId'] == movie_id_test_from_ratings]['title'].iloc[0]\n",
    "        print(f\"Testing SVD prediction for user {user_id_test} on movie {movie_id_test_from_ratings} ('{movie_title_for_test}').\")\n",
    "        prediction_example = svd_full.predict(user_id_test, movie_id_test_from_ratings)\n",
    "        print(f\"Predicted rating: {prediction_example.est:.2f}\")\n",
    "    else:\n",
    "        movie_id_test_from_ratings = None\n",
    "        print(\"No suitable movie found for example prediction between df_rated_movies and ratings. Skipping example.\")\n",
    "\n",
    "\n",
    "    def recommend_movies_svd(user_id, svd_model=svd_full, df_all_movies=df_rated_movies, num_recommendations=10):\n",
    "        user_train_rated_movie_ids = set()\n",
    "        if user_id in svd_model.trainset._raw2inner_id_users:\n",
    "            inner_user_id = svd_model.trainset.to_inner_uid(user_id)\n",
    "            user_train_rated_movie_ids_inner = {iid for iid, _ in svd_model.trainset.ur[inner_user_id]}\n",
    "            user_train_rated_movie_ids = {svd_model.trainset.to_raw_iid(inner_iid) for inner_iid in user_train_rated_movie_ids_inner}\n",
    "\n",
    "        predictions_list = []\n",
    "        all_known_raw_iids_from_model = {svd_model.trainset.to_raw_iid(inner_id) for inner_id in svd_model.trainset.all_items()}\n",
    "        \n",
    "        movies_to_predict = df_all_movies[df_all_movies['movieId'].isin(list(all_known_raw_iids_from_model))]\n",
    "        \n",
    "        for _, row in movies_to_predict.iterrows():\n",
    "            movie_id = row['movieId']\n",
    "            if movie_id not in user_train_rated_movie_ids:\n",
    "                prediction = svd_model.predict(user_id, movie_id)\n",
    "                predictions_list.append({'movieId': movie_id, 'predicted_rating': prediction.est})\n",
    "\n",
    "        if not predictions_list:\n",
    "            print(f\"User {user_id} has no unrated movies from the available set that also have full metadata.\")\n",
    "            return pd.DataFrame(columns=['title', 'predicted_rating', 'vote_average', 'vote_count', 'score'])\n",
    "\n",
    "        predictions_df = pd.DataFrame(predictions_list)\n",
    "        predictions_df = predictions_df.sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "        top_recommendations = pd.merge(\n",
    "            predictions_df,\n",
    "            df_all_movies[['movieId', 'title', 'vote_average', 'vote_count', 'score']],\n",
    "            on='movieId',\n",
    "            how='left'\n",
    "        )\n",
    "        top_recommendations.drop_duplicates(subset=['title'], inplace=True)\n",
    "        return top_recommendations.head(num_recommendations)\n",
    "\n",
    "    print(\"\\n--- Testing Collaborative Filtering (SVD) Recommender for User 1 (trained on full data) ---\")\n",
    "    user_to_test_svd = 1\n",
    "    top_10_recs_svd = recommend_movies_svd(user_to_test_svd, num_recommendations=10)\n",
    "    print(f\"Top 10 SVD Recommendations for User ID {user_to_test_svd}:\")\n",
    "    print(top_10_recs_svd.to_string())\n",
    "\n",
    "else:\n",
    "    print(\"Collaborative filtering part not executed because 'ratings_small.csv' was not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de4738-af66-4313-98a6-e3d16f4013e3",
   "metadata": {},
   "source": [
    "<a id='evaluation-metrics'></a>\n",
    "## 5. Phase 4: Evaluation and Metrics\n",
    "\n",
    "Evaluating a recommendation system is critical to understanding its performance. Beyond basic predictive accuracy metrics (like RMSE and MAE for Collaborative Filtering), we also need to assess the quality of the *ranked lists* of recommendations generated by content-based and hybrid models.\n",
    "\n",
    "### Key Metrics:\n",
    "\n",
    "1.  **Precision@K:** Of the top K recommendations, what proportion are relevant (liked) to the user?\n",
    "    *   `Precision@K = (Number of relevant items in top K) / K`\n",
    "2.  **Recall@K:** Of all the relevant (liked) items, what proportion did the model recommend in its top K list?\n",
    "    *   `Recall@K = (Number of relevant items in top K) / (Total number of relevant items)`\n",
    "3.  **F1-Score@K:** The harmonic mean of Precision and Recall, providing a single metric that balances both.\n",
    "    *   `F1-Score@K = 2 * (Precision * Recall) / (Precision + Recall)`\n",
    "\n",
    "### Ground Truth for \"Liked\" Movies:\n",
    "\n",
    "For evaluation, we define a movie as \"liked\" by a user if they rated it **4.0 stars or higher** in the `ratings_small.csv` dataset. This acts as our ground truth for determining relevance.\n",
    "\n",
    "We will evaluate the performance for content-based and hybrid models by comparing their recommendations for certain seed movies (and associated users) against the ground truth. Collaborative filtering already provides RMSE/MAE, but we will also calculate Precision/Recall for it using a test set split.\n",
    "\n",
    "**Note:** Achieving very high Precision/Recall on real-world, sparse datasets like MovieLens Small with limited `K` (e.g., 10) is challenging. Low but non-zero scores indicate successful matching, but also highlight the inherent difficulty and sparsity of recommendation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c034ee53-5378-48db-bbf2-8321f9341702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 3: Evaluation and Metrics ---\n",
      "Generated 'liked movies' sets for 671 users (threshold >= 4.0 stars).\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation and Metrics Section ---\n",
    "print(\"\\n--- Phase 3: Evaluation and Metrics ---\")\n",
    "\n",
    "RATING_THRESHOLD = 4.0 # Definition of 'liked'\n",
    "\n",
    "# user_liked_movies: maps userId to a SET of movieId that they rated >= RATING_THRESHOLD\n",
    "user_liked_movies = {} \n",
    "for user_id in ratings['userId'].unique():\n",
    "    liked_movie_ids_from_ratings = ratings[(ratings['userId'] == user_id) & (ratings['rating'] >= RATING_THRESHOLD)]['movieId'].tolist()\n",
    "    # Ensure these liked movies are in our `df_rated_movies` for consistent evaluation context\n",
    "    user_liked_movies[user_id] = set(df_rated_movies[df_rated_movies['movieId'].isin(liked_movie_ids_from_ratings)]['movieId'].tolist())\n",
    "\n",
    "print(f\"Generated 'liked movies' sets for {len(user_liked_movies)} users (threshold >= {RATING_THRESHOLD} stars).\")\n",
    "\n",
    "\n",
    "def precision_at_k(recommended_items_ids, liked_items_ids, k):\n",
    "    recommended_k = set(recommended_items_ids[:k])\n",
    "    num_hit_items = len(recommended_k.intersection(liked_items_ids))\n",
    "    return num_hit_items / k if k > 0 else 0\n",
    "\n",
    "def recall_at_k(recommended_items_ids, liked_items_ids, k):\n",
    "    recommended_k = set(recommended_items_ids[:k])\n",
    "    num_hit_items = len(recommended_k.intersection(liked_items_ids))\n",
    "    num_liked_items = len(liked_items_ids)\n",
    "    return num_hit_items / num_liked_items if num_liked_items > 0 else 0\n",
    "\n",
    "def f1_score_at_k(precision, recall):\n",
    "    if (precision + recall) == 0:\n",
    "        return 0\n",
    "    return 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69cad20c-85cf-4c55-8903-62ab04d395fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Content-Based and Hybrid Recommenders (using MovieLens IDs) ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating Content-Based and Hybrid Recommenders (using MovieLens IDs) ---\")\n",
    "\n",
    "test_movie_titles = ['Toy Story', 'Finding Nemo', 'The Shawshank Redemption', 'Pulp Fiction']\n",
    "eval_results = []\n",
    "K_value = 10\n",
    "\n",
    "for title_of_base_movie in test_movie_titles:\n",
    "    if title_of_base_movie not in title_to_index:\n",
    "        print(f\"'{title_of_base_movie}' not found in DataFrame index map. Skipping evaluation for this movie.\")\n",
    "        continue\n",
    "        \n",
    "    base_movie_movieId = df.loc[title_to_index[title_of_base_movie], 'movieId']\n",
    "    relevant_users_for_base_movie = ratings[ratings['movieId'] == base_movie_movieId]['userId'].unique()\n",
    "    \n",
    "    if len(relevant_users_for_base_movie) == 0:\n",
    "        print(f\"No users rated '{title_of_base_movie}' (MovieID: {base_movie_movieId}) in the ratings dataset. Skipping content-based evaluation for this movie.\")\n",
    "        continue\n",
    "\n",
    "    # Evaluate across a few relevant users for robustness (average their P/R/F1)\n",
    "    users_to_evaluate_against = relevant_users_for_base_movie[:5] \n",
    "    \n",
    "    for eval_user_id in users_to_evaluate_against:\n",
    "        user_true_likes_movieIds = user_liked_movies.get(eval_user_id, set())\n",
    "\n",
    "        if not user_true_likes_movieIds:\n",
    "            # print(f\"User {eval_user_id} has no liked movies (>= {RATING_THRESHOLD} stars) in metadata for '{title_of_base_movie}'. Skipping for this user.\")\n",
    "            continue # Skip users with no liked movies\n",
    "\n",
    "        # --- Content-Based (Plot) ---\n",
    "        rec_plot_df = get_recommendations_plot_refined(title_of_base_movie, df_movies=df, title_map=title_to_index)\n",
    "        # Convert recommended *titles* from `rec_plot_df` to their *MovieLens movieIds* via `df_rated_movies`\n",
    "        plot_recommended_movie_ids = df_rated_movies[df_rated_movies['title'].isin(rec_plot_df['title'])]['movieId'].tolist()\n",
    "\n",
    "        p_plot = precision_at_k(plot_recommended_movie_ids, user_true_likes_movieIds, K_value)\n",
    "        r_plot = recall_at_k(plot_recommended_movie_ids, user_true_likes_movieIds, K_value)\n",
    "        f1_plot = f1_score_at_k(p_plot, r_plot)\n",
    "        eval_results.append({\n",
    "            'Movie': title_of_base_movie, 'Method': 'Content (Plot)', 'User': eval_user_id,\n",
    "            'Precision@K': f\"{p_plot:.4f}\", 'Recall@K': f\"{r_plot:.4f}\", 'F1-Score@K': f\"{f1_plot:.4f}\",\n",
    "            'Num_Liked': len(user_true_likes_movieIds)\n",
    "        })\n",
    "\n",
    "        # --- Content-Based (Metadata) ---\n",
    "        rec_meta_df = get_recommendations_metadata_refined(title_of_base_movie, df_movies=df, title_map=title_to_index)\n",
    "        meta_recommended_movie_ids = df_rated_movies[df_rated_movies['title'].isin(rec_meta_df['title'])]['movieId'].tolist()\n",
    "\n",
    "        p_meta = precision_at_k(meta_recommended_movie_ids, user_true_likes_movieIds, K_value)\n",
    "        r_meta = recall_at_k(meta_recommended_movie_ids, user_true_likes_movieIds, K_value)\n",
    "        f1_meta = f1_score_at_k(p_meta, r_meta)\n",
    "        eval_results.append({\n",
    "            'Movie': title_of_base_movie, 'Method': 'Content (Metadata)', 'User': eval_user_id,\n",
    "            'Precision@K': f\"{p_meta:.4f}\", 'Recall@K': f\"{r_meta:.4f}\", 'F1-Score@K': f\"{f1_meta:.4f}\",\n",
    "            'Num_Liked': len(user_true_likes_movieIds)\n",
    "        })\n",
    "        \n",
    "        # --- Hybrid (Plot + Weighted Rating) ---\n",
    "        rec_hybrid_df = get_hybrid_recommendations_content_weighted(title_of_base_movie, content_source='plot', df_movies=df, title_map=title_to_index)\n",
    "        hybrid_recommended_movie_ids = df_rated_movies[df_rated_movies['title'].isin(rec_hybrid_df['title'])]['movieId'].tolist()\n",
    "\n",
    "        p_hybrid = precision_at_k(hybrid_recommended_movie_ids, user_true_likes_movieIds, K_value)\n",
    "        r_hybrid = recall_at_k(hybrid_recommended_movie_ids, user_true_likes_movieIds, K_value)\n",
    "        f1_hybrid = f1_score_at_k(p_hybrid, r_hybrid)\n",
    "        eval_results.append({\n",
    "            'Movie': title_of_base_movie, 'Method': 'Hybrid (Plot+WR)', 'User': eval_user_id,\n",
    "            'Precision@K': f\"{p_hybrid:.4f}\", 'Recall@K': f\"{r_hybrid:.4f}\", 'F1-Score@K': f\"{f1_hybrid:.4f}\",\n",
    "            'Num_Liked': len(user_true_likes_movieIds)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfdcd407-03fb-416e-81f5-9ce86f1d7312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results Summary (K=10, Averaged per movie/method across relevant users) ---\n",
      "                       Movie              Method Precision  Recall F1_Score  Avg_Num_Liked\n",
      "0               Finding Nemo  Content (Metadata)    0.0200  0.0005   0.0010          116.2\n",
      "1               Finding Nemo      Content (Plot)    0.0000  0.0000   0.0000          116.2\n",
      "2               Finding Nemo    Hybrid (Plot+WR)    0.0000  0.0000   0.0000          116.2\n",
      "3               Pulp Fiction  Content (Metadata)    0.0400  0.0058   0.0101           64.0\n",
      "4               Pulp Fiction      Content (Plot)    0.0000  0.0000   0.0000           64.0\n",
      "5               Pulp Fiction    Hybrid (Plot+WR)    0.0000  0.0000   0.0000           64.0\n",
      "6   The Shawshank Redemption  Content (Metadata)    0.0200  0.0029   0.0051           37.2\n",
      "7   The Shawshank Redemption      Content (Plot)    0.0000  0.0000   0.0000           37.2\n",
      "8   The Shawshank Redemption    Hybrid (Plot+WR)    0.0000  0.0000   0.0000           37.2\n",
      "9                  Toy Story  Content (Metadata)    0.0200  0.0071   0.0105          138.8\n",
      "10                 Toy Story      Content (Plot)    0.0400  0.0081   0.0124          138.8\n",
      "11                 Toy Story    Hybrid (Plot+WR)    0.0400  0.0081   0.0124          138.8\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluation Results Summary (K=10, Averaged per movie/method across relevant users) ---\")\n",
    "if eval_results:\n",
    "    eval_df = pd.DataFrame(eval_results)\n",
    "    avg_eval_df = eval_df.groupby(['Movie', 'Method']).agg(\n",
    "        Precision=('Precision@K', lambda x: f\"{pd.to_numeric(x).mean():.4f}\"),\n",
    "        Recall=('Recall@K', lambda x: f\"{pd.to_numeric(x).mean():.4f}\"),\n",
    "        F1_Score=('F1-Score@K', lambda x: f\"{pd.to_numeric(x).mean():.4f}\"),\n",
    "        Avg_Num_Liked=('Num_Liked', 'mean')\n",
    "    ).reset_index()\n",
    "    print(avg_eval_df.to_string())\n",
    "else:\n",
    "    print(\"No evaluation results were generated. Check if test movies are correctly mapped or if users have liked movies.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08999292-21a5-4e61-9a0e-99232e064257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
